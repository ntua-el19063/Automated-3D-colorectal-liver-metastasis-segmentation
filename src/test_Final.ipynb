{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PuU_tzIf1Y7"
      },
      "outputs": [],
      "source": [
        "# Install MONAI\n",
        "import sys\n",
        "!{sys.executable} -m pip install monai==1.3.0 -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvgJlkQHf6bS"
      },
      "outputs": [],
      "source": [
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    EnsureChannelFirstD,\n",
        "    LoadImaged,\n",
        "    DivisiblePadD,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    Activations,\n",
        "    ConcatItemsd,\n",
        "    Compose,\n",
        "    AsDiscrete,\n",
        ")\n",
        "\n",
        "from monai.networks.nets import UNet, SegResNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
        "from monai.metrics import DiceMetric, SurfaceDistanceMetric\n",
        "from monai.inferers import sliding_window_inference\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.ndimage import label as cc_label\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_dir = r'path/to/data_split' # path to data split folders\n",
        "model_dir = r'path/to/results' #Path to best checkpoint folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
        "train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
        "val_loss = np.load(os.path.join(model_dir, 'loss_val.npy'))\n",
        "val_metric = np.load(os.path.join(model_dir, 'metric_val.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Visualize metric curves from training\n",
        "\n",
        "plt.figure(\"Metric Results Best SegResNet\", (12, 6))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Train dice loss\")\n",
        "x = [i + 1 for i in range(len(train_loss))]\n",
        "y = train_loss\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(\"Train metric DICE\")\n",
        "x = [i + 1 for i in range(len(train_metric))]\n",
        "y = train_metric\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(\"Test dice loss\")\n",
        "x = [i + 1 for i in range(len(val_loss))]\n",
        "y = val_loss\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title(\"Test metric DICE\")\n",
        "x = [i + 1 for i in range(len(val_metric))]\n",
        "y = val_metric\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset paths\n",
        "path_test_volumes = sorted(glob(os.path.join(in_dir, \"OptimTestVol\", \"*.nii.gz\")))\n",
        "path_test_seg_tumors = sorted(glob(os.path.join(in_dir, \"OptimTestSegTumors\", \"*.nii.gz\")))\n",
        "path_test_seg_liver = sorted(glob(os.path.join(in_dir, \"OptimTestSegLiverPred\", \"*.nii.gz\")))\n",
        "\n",
        "test_files = [{\"vol\": vol, \"seg_tumor\": seg_tumor, \"seg_liver\": seg_liver} \n",
        "              for vol, seg_tumor, seg_liver in zip(path_test_volumes, path_test_seg_tumors, path_test_seg_liver)]\n",
        "\n",
        "#print(f\"Found {len(path_test_volumes)} volumes, {len(path_test_seg_tumors)} tumors, {len(path_test_seg_liver)} livers for testing.\")\n",
        "#print(f\"Final test file triplets: {len(test_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixdim=(1.0, 1.0, 2.5)\n",
        "a_min=-100\n",
        "a_max=200\n",
        "\n",
        "test_transforms = Compose([\n",
        "        LoadImaged(keys=[\"vol\", \"seg_tumor\", \"seg_liver\"]),\n",
        "        EnsureChannelFirstD(keys=[\"vol\", \"seg_tumor\", \"seg_liver\"]),\n",
        "\n",
        "        Spacingd(keys=[\"vol\", \"seg_tumor\", \"seg_liver\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\", \"nearest\")),\n",
        "        Orientationd(keys=[\"vol\", \"seg_tumor\", \"seg_liver\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
        "\n",
        "        CropForegroundd(keys=[\"vol\", \"seg_tumor\", \"seg_liver\"], source_key=\"seg_liver\"), \n",
        "\n",
        "        DivisiblePadD(keys=[\"vol\", \"seg_tumor\",\"seg_liver\"], k=16, mode=\"constant\"),\n",
        "        \n",
        "        ConcatItemsd(keys=[\"vol\", \"seg_liver\"], name=\"conc_image\", dim=0),\n",
        "\n",
        "        ToTensord(keys=[\"conc_image\", \"seg_tumor\"])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model = SegResNet(\n",
        "        spatial_dims=3,\n",
        "        init_filters=16,\n",
        "        in_channels=2,\n",
        "        out_channels=2,\n",
        "        dropout_prob=0.1,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Load best weights & config ----\n",
        "ckpt_path = os.path.join(model_dir, \"best_metric_model.pth\")\n",
        "model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regular Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TESTING SETUP\n",
        " \n",
        "roi_size = (128, 128, 64)\n",
        "sw_batch_size = 1\n",
        "overlap = 0.4\n",
        "\n",
        "from monai.metrics import DiceMetric\n",
        "\n",
        "dice_metric_case = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "surf_metric = SurfaceDistanceMetric(include_background=False, symmetric=True)\n",
        "surface_metric = SurfaceDistanceMetric(include_background=False, symmetric=True)\n",
        "\n",
        "# Post transforms for DiceMetric (multi-class with background excluded)\n",
        "\n",
        "post_pred  = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
        "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
        "\n",
        "# ---- (Optional) simple recall/precision helpers (voxel-wise, class=1) ----\n",
        "def _recall_precision_from_masks(pred_bin: torch.Tensor, gt_bin: torch.Tensor):\n",
        "    \"\"\"pred_bin/gt_bin: [1,1,H,W,D] binary {0,1} tensors\"\"\"\n",
        "    p = pred_bin > 0.5\n",
        "    g = gt_bin > 0.5\n",
        "    tp = (p & g).sum().float()\n",
        "    fp = (p & ~g).sum().float()\n",
        "    fn = (~p & g).sum().float()\n",
        "    recall = (tp / (tp + fn + 1e-8)).item()\n",
        "    precision = (tp / (tp + fp + 1e-8)).item()\n",
        "    return recall, precision\n",
        "\n",
        "def _summ(name, arr):\n",
        "    arr = np.asarray(arr, dtype=float)\n",
        "    mean, std = np.nanmean(arr), np.nanstd(arr)\n",
        "    mn, mx = np.nanmin(arr), np.nanmax(arr)\n",
        "    print(f\"{name:>10}: {mean:.4f} Â± {std:.4f} | min={mn:.4f} | max={mx:.4f}\")\n",
        "\n",
        "def dice_from_confusion(tp, fp, fn, eps=1e-8):\n",
        "    return (2 * tp) / (2 * tp + fp + fn + eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MASK COMPRAISON - original, liver-pred mask, tumor-pred mask  ---\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "\n",
        "idx, z = 4, 51\n",
        "\n",
        "# 1) Load volume\n",
        "case = test_ds[idx]\n",
        "vol  = case[\"conc_image\"][0].cpu().numpy()\n",
        "assert 0 <= z < vol.shape[2], f\"Slice {z} out of range 0..{vol.shape[2]-1}\"\n",
        "\n",
        "# 2) Load liver prediction mask\n",
        "def get_liver_pred_for_index(i):\n",
        "    if \"seg_liver\" in case and case[\"seg_liver\"] is not None:\n",
        "        return (case[\"seg_liver\"][0].cpu().numpy() > 0).astype(np.uint8)\n",
        "    lp = nib.load(path_test_seg_liver[i]).get_fdata()\n",
        "    lp = np.squeeze(lp)\n",
        "    return (lp > 0).astype(np.uint8)\n",
        "\n",
        "liver_pred = get_liver_pred_for_index(idx)\n",
        "z_liver = min(z, liver_pred.shape[2]-1)\n",
        "\n",
        "# 3) Run tumor prediction for this case\n",
        "with torch.no_grad():\n",
        "    inp = case[\"conc_image\"].unsqueeze(0).to(device)\n",
        "    logits = sliding_window_inference(inp, roi_size, sw_batch_size, predictor=model, overlap=overlap)\n",
        "    if isinstance(logits, list):\n",
        "        logits = logits[-1]\n",
        "    tumor_pred_full = torch.argmax(logits, dim=1)[0].cpu().numpy()\n",
        "\n",
        "tumor_pred = (tumor_pred_full == 1).astype(np.uint8)\n",
        "z_tumor = min(z, tumor_pred.shape[2]-1)\n",
        "\n",
        "# 4) Plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Original\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(vol[:, :, z], cmap=\"gray\")\n",
        "plt.title(f\"Original (idx={idx}, z={z})\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Liver prediction mask (white on black)\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(liver_pred[:, :, z_liver], cmap=\"gray\", vmin=0, vmax=1)\n",
        "plt.title(\"Liver Prediction Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Tumor prediction mask (white on black)\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(tumor_pred[:, :, z_tumor], cmap=\"gray\", vmin=0, vmax=1)\n",
        "plt.title(\"Tumor Prediction Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#METRIC COMPUTATION\n",
        "\n",
        "# global Dice like training\n",
        "test_tp = torch.tensor(0, device=device)\n",
        "test_fp = torch.tensor(0, device=device)\n",
        "test_fn = torch.tensor(0, device=device)\n",
        "\n",
        "per_case_metrics = []\n",
        "case_idx = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        vol = batch[\"conc_image\"].to(device)               # Add 2-channel vol\n",
        "        gt  = (batch[\"seg_tumor\"] != 0).long().to(device)  \n",
        "\n",
        "        logits = sliding_window_inference(\n",
        "            vol, roi_size, sw_batch_size, model, overlap=overlap\n",
        "        )\n",
        "                # decollate\n",
        "        logits_list = decollate_batch(logits)  # each: [C,H,W,D]\n",
        "        gts_list    = decollate_batch(gt)      # each: [1,H,W,D]\n",
        "\n",
        "        for logit_i, gt_i in zip(logits_list, gts_list):\n",
        "            # ---- Dice (matching training) ----\n",
        "            y_pred_i = post_pred(logit_i)        \n",
        "            y_true_i = post_label(gt_i)      \n",
        "\n",
        "            dice_metric_case.reset()\n",
        "            dice_metric_case(y_pred=[y_pred_i], y=[y_true_i])\n",
        "            dice_val = dice_metric_case.aggregate().item()\n",
        "            dice_metric_case.reset()\n",
        "\n",
        "            #  Binary masks for ASSD / recall / precision \n",
        "            pred_label = torch.argmax(logit_i, dim=0)  \n",
        "            pred_bin   = (pred_label == 1).float().unsqueeze(0).unsqueeze(0).to(device)  \n",
        "            gt_bin     = (gt_i == 1).float().unsqueeze(0).to(device)                     \n",
        "\n",
        "            # ASSD\n",
        "            if (pred_bin.sum() > 0) and (gt_bin.sum() > 0):\n",
        "                surf_metric.reset()\n",
        "                surf_metric(y_pred=pred_bin, y=gt_bin)\n",
        "                try:\n",
        "                    assd_val = surf_metric.aggregate().item()\n",
        "                except (ValueError, AttributeError):\n",
        "                    assd_val = np.nan\n",
        "                surf_metric.reset()\n",
        "            else:\n",
        "                assd_val = np.nan\n",
        "\n",
        "            # Recall / Precision\n",
        "            recall_val, precision_val = _recall_precision_from_masks(pred_bin, gt_bin)\n",
        "\n",
        "            # accumulate confusion for global Dice like training\n",
        "            tp_i = (pred_bin.bool() & gt_bin.bool()).sum()\n",
        "            fp_i = (pred_bin.bool() & ~gt_bin.bool()).sum()\n",
        "            fn_i = (~pred_bin.bool() & gt_bin.bool()).sum()\n",
        "            test_tp += tp_i\n",
        "            test_fp += fp_i\n",
        "            test_fn += fn_i\n",
        "\n",
        "            per_case_metrics.append({\n",
        "                \"idx\": case_idx,\n",
        "                \"dice\": float(dice_val),\n",
        "                \"assd\": float(assd_val) if assd_val == assd_val else np.nan,\n",
        "                \"recall\": float(recall_val),\n",
        "                \"precision\": float(precision_val),\n",
        "            })\n",
        "            case_idx += 1\n",
        "\n",
        "\n",
        "dice_vals      = [m[\"dice\"] for m in per_case_metrics]\n",
        "assd_vals      = [m[\"assd\"] for m in per_case_metrics]\n",
        "recall_vals    = [m[\"recall\"] for m in per_case_metrics]\n",
        "precision_vals = [m[\"precision\"] for m in per_case_metrics]\n",
        "\n",
        "_summ(\"Dice\", dice_vals)\n",
        "_summ(\"ASSD\", assd_vals)\n",
        "_summ(\"Recall\", recall_vals)\n",
        "_summ(\"Precision\", precision_vals)\n",
        "\n",
        "\n",
        "\n",
        "final_global_dice = dice_from_confusion(test_tp.float(), test_fp.float(), test_fn.float()).item()\n",
        "print(f\"Global Dice (from TP/FP/FN): {final_global_dice:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## OUTLIER BINS - per-patient DICE\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "valid_items = [(m[\"idx\"], m[\"dice\"]) for m in per_case_metrics if not np.isnan(m[\"dice\"])]\n",
        "if len(valid_items) == 0:\n",
        "    print(\"No valid per-case Dice values . Nothing to plot.\")\n",
        "else:\n",
        "    idxs  = np.array([it[0] for it in valid_items], dtype=int)\n",
        "    dscs  = np.array([it[1] for it in valid_items], dtype=float)\n",
        "    dscs_pct = np.clip(dscs * 100.0, 0.0, 100.0)\n",
        "\n",
        "    # Define bins and labels\n",
        "    bins   = [0, 20, 40, 60, 80, 100]\n",
        "    labels = [\"0â20\", \"20â40\", \"40â60\", \"60â80\", \"80â100\"]\n",
        "\n",
        "    counts, edges = np.histogram(dscs_pct, bins=bins)\n",
        "\n",
        "    # Map patients to bins (for quick outlier inspection)\n",
        "    bin_to_patients = {lab: [] for lab in labels}\n",
        "    # np.digitize returns bin indices in 1..len(bins)-1 with left-closed right-open, except rightmost\n",
        "    bin_indices = np.digitize(dscs_pct, bins=bins, right=False)\n",
        "    # Ensure values equal to the upper edge 100 land in last bin\n",
        "    bin_indices = np.clip(bin_indices, 1, len(bins)-1)\n",
        "\n",
        "    for pid, b in zip(idxs, bin_indices):\n",
        "        bin_to_patients[labels[b-1]].append(int(pid))\n",
        "\n",
        "    # --- Plot ---\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.bar(labels, counts)\n",
        "    plt.xlabel(\"Per-case Dice\")\n",
        "    plt.ylabel(\"Number of patients\")\n",
        "    plt.title(f\"Dice distribution across patients for automated pipeline (N={len(dscs_pct)} included)\")\n",
        "\n",
        "    # Set the y-axis limits from 0 to 20\n",
        "    plt.ylim(0, 20)\n",
        "\n",
        "    # Annotate counts on bars\n",
        "    for i, c in enumerate(counts):\n",
        "        plt.text(i, c + max(1, 0.02*max(counts) if counts.max() > 0 else 1), str(int(c)),\n",
        "                 ha=\"center\", va=\"bottom\", fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print patient indices per bin with Dice scores\n",
        "    print(\"\\nPatients per Dice bin (with Dice scores):\")\n",
        "    for lab in labels:\n",
        "        patients = bin_to_patients[lab]\n",
        "        if patients:\n",
        "            pid_scores = [(pid, round(float(dscs_pct[idxs == pid][0]) / 100.0, 3)) \n",
        "                          for pid in patients]\n",
        "            print(f\"  {lab}%: {pid_scores}\")\n",
        "        else:\n",
        "            print(f\"  {lab}%: []\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DICE WITHOUT OUTLIERS\n",
        "\n",
        "excluded_ids = set(bin_to_patients[labels[0]] + bin_to_patients[labels[1]])\n",
        "\n",
        "orig_dice = [m[\"dice\"] for m in per_case_metrics if not np.isnan(m[\"dice\"])]\n",
        "\n",
        "filtered_dice = [m[\"dice\"] for m in per_case_metrics\n",
        "                 if (not np.isnan(m[\"dice\"])) and (m[\"idx\"] not in excluded_ids)]\n",
        "\n",
        "if len(filtered_dice) == 0:\n",
        "    print(\"No remaining patients after excluding the first two bins.\")\n",
        "else:\n",
        "    final_test_dice_excl_low = float(np.mean(filtered_dice))\n",
        "    print(f\"Excluded patient IDs (first two bins): {sorted(excluded_ids)}\")\n",
        "    print(f\"N included: {len(filtered_dice)} / {len(orig_dice)} total\")\n",
        "    print(f\"Recomputed test Dice (mean) excluding outliers: {final_test_dice_excl_low:.4f}\")\n",
        "    print(f\"Median: {np.median(filtered_dice):.4f} | Std: {np.std(filtered_dice, ddof=1):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Option 1 - Select patients\n",
        "indices = [10, 12]\n",
        "\n",
        "#Option 2 - Random selection\n",
        "# num_patients = 5\n",
        "# total_cases = len(test_ds)\n",
        "# indices = random.sample(range(total_cases), num_patients)  # unique random indicesslice_stride = 1          # show every k-th slice containing GT or Pred; 1 = show all\n",
        "\n",
        "slice_stride = 1 \n",
        "\n",
        "\n",
        "shown = 0\n",
        "with torch.no_grad():\n",
        "    for idx in indices:\n",
        "        \n",
        "\n",
        "        case = test_ds[idx]\n",
        "        inp = case[\"conc_image\"].unsqueeze(0).to(device)  # [1,1,H,W,D]\n",
        "        logits = sliding_window_inference(inp, roi_size, sw_batch_size, predictor=model, overlap=overlap)\n",
        "        if isinstance(logits, list):\n",
        "            logits = logits[-1]\n",
        "        pred = torch.argmax(logits, dim=1)[0].cpu().numpy()     # [H,W,D]\n",
        "\n",
        "        vol = case[\"conc_image\"][0].cpu().numpy()                      # [H,W,D]\n",
        "        gt  = case[\"seg_tumor\"][0].cpu().numpy()                # [H,W,D]\n",
        "\n",
        "        zs_gt   = np.where(gt.sum(axis=(0, 1)) > 0)[0]\n",
        "        zs_pred = np.where(pred.sum(axis=(0, 1)) > 0)[0]\n",
        "        zs = np.unique(np.concatenate([zs_gt, zs_pred]))\n",
        "        if len(zs) == 0:\n",
        "            print(f\"\\nPatient index: {idx} had no slices with tumor in GT or Pred.\")\n",
        "            zmid = vol.shape[2] // 2\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 3, 1); plt.imshow(vol[:, :, zmid], cmap=\"gray\"); plt.title(f\"Axial z={zmid}\")\n",
        "            plt.subplot(1, 3, 2); plt.imshow(vol[:, :, zmid], cmap=\"gray\"); plt.title(\"GT contour (none)\")\n",
        "            plt.subplot(1, 3, 3); plt.imshow(vol[:, :, zmid], cmap=\"gray\"); plt.title(\"Pred contour (none)\")\n",
        "            plt.tight_layout(); plt.show()\n",
        "            shown += 1\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nPatient index: {idx} | tumor slices (GT âª Pred): {len(zs)}\")\n",
        "\n",
        "        for z in zs[::slice_stride]:\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(vol[:, :, z], cmap=\"gray\")\n",
        "            plt.title(f\"Axial z={z}\")\n",
        "\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(vol[:, :, z], cmap=\"gray\")\n",
        "            # GT contour\n",
        "            if (gt[:, :, z] > 0).any():\n",
        "                plt.contour(gt[:, :, z], levels=[0.5], linewidths=1.5, colors='lime')\n",
        "            plt.title(\"GT contour\")\n",
        "\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(vol[:, :, z], cmap=\"gray\")\n",
        "            # Pred contour\n",
        "            if (pred[:, :, z] > 0).any():\n",
        "                plt.contour(pred[:, :, z], levels=[0.5], linewidths=1.5, colors='lime')\n",
        "            plt.title(\"2-channel SegRes Pred\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        shown += 1\n",
        "\n",
        "if shown == 0:\n",
        "    print(\"No patients with tumor slices found in test set.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
